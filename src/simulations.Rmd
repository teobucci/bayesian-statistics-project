---
title: "Simulations (copy of Esempio_funzioni.Rmd)"
author: "Teo Bucci"
date: "2023-01-02"
output: pdf_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
suppressWarnings(suppressPackageStartupMessages(library(tidyverse)))
suppressWarnings(suppressPackageStartupMessages(library(ACutils)))
suppressWarnings(suppressPackageStartupMessages(library(mvtnorm)))
suppressWarnings(suppressPackageStartupMessages(library(salso)))
#suppressWarnings(suppressPackageStartupMessages(library(mcclust.ext)))
#setwd("~/Documents/GitHub/bayesian-statistics-project/src")
```

## Generate data from the model

```{r}
# copy and paste from functions.R
Generate_data = function(n,p,z=NULL,W=NULL,seed=123421){
    
    nu = max(n,p) # default choice of nu
    if(n<p)
        stop("p can not be larger than n")
    
    if(is.null(z)){ #default is 3 groups
        if(p<3)
            stop("p must be greater than 3 if z is defaulted")
        z = vector(length = p)
        z[1:ceiling(p/3)] = 1
        z[(ceiling(p/3)+1):(2*ceiling(p/3))] = 2
        z[(2*ceiling(p/3)+1):p] = 3
    }else{
        if(p != length(z))
            stop("the length of z should be p")
    }
    
    if(is.null(W)){ #default is to sample a W from Wishart(nu, I_p)
        D = diag(p)
        set.seed(seed)
        W = MCMCpack::rwish(nu,D)
    }
    
    # Generate V
    V = ComputeV(nu,W,z)
    
    # Generate Omega
    Omega = MCMCpack::rwish(nu,V)
    
    # Compute Sigma (inefficient)
    Sigma = solve(Omega)
    
    # Generate data
    data = matrix(NA,nrow = n, ncol = p)
    data = t(apply(data, 1, FUN = function(x){ mvtnorm::rmvnorm(n = 1, sigma = Sigma)  }))
    
    #return 
    return(list("data" = data,
                "Omega" = Omega,
                "Sigma" = Sigma,
                "V"     = V,
                "z_true"= z
    ))
}


ComputeV = function(nu,W,z){
    p = dim(W)[1] #get dimension
    if(length(z)!=p)
        stop("length of z is different from nrow(W)")
    if(nu<=0)
        stop("nu can not be negative or zero")
    
    V = matrix(0,nrow = p,ncol = p) 
    # fill the upper triangular part of V
    for(i in 1:p){
        for(j in (i+1):p){
            if(j>p)break; #needed because r for loops sucks
            if(z[i]==z[j])
                V[i,j] = W[i,j]/nu #just see the definition
        }
    }
    V = V + t(V) #set the lower trg part
    diag(V) = diag(W)/nu #set the diagonal
    return (V)
}
```


```{r}
# Plot V
#ACutils::ACheatmap(V,use_x11_device = F,horizontal = F)

# Plot Omega
#ACutils::ACheatmap(Omega_true,use_x11_device = F,horizontal = F)

#Plot empirical estimate
#ACutils::ACheatmap(solve(cov(data)),use_x11_device = F,horizontal = F)
```

a)  Fit the model with fixed partition

```{r}
#W = solve(cov(data))
#nu = max(n,p)
library("FGM")

utility_path = file.path("utility_functions.R")
file.exists(utility_path)
source(utility_path)

bulky_path = file.path("bulky_functions.R")
file.exists(bulky_path)
source(bulky_path)

data_generation_path = file.path("data_generation.R")
file.exists(data_generation_path)
source(data_generation_path)


z_true = c(1,1,1,2,2,3,3,3,4,4) # these are the groups memberships (10 nodes)
counts_true = as.vector(table(z_true))
Nclust_true  = length(counts_true)

p = length(z_true)
n = 100
data_from_prior = Generate_data(n=n,p=p,z=z_true,seed=27091999)
nu = n # why?
data = data_from_prior$data
Omega_true = data_from_prior$Omega # Omega is Kappa (precision matrix TODO change)
Sigma_true = data_from_prior$Sigma
V = data_from_prior$V # cos'Ã¨?
U = t(data)%*%data

options = set_options(sigma0=0.5,
                      sigma_parameters=c(1,1,1,1),
                      theta_prior0=1,
                      theta_parameters=c(1,1),
                      rho0=c(5,5),
                      weights_a0=rep(1,p-1),
                      weights_d0=rep(1,p-1),
                      alpha_target=0.40,
                      mu_beta=0.5, # mu of the Beta
                      sig2_beta=0.2, # variance of the Beta
                      d=3,
                      alpha_add=0.5,
                      adaptation_step=0.5,
                      update_sigma=F,
                      update_theta_prior=F,
                      update_weights=T,
                      update_partition=T,
                      update_graph=F,
                      perform_shuffle=T)

niter = 5000
nburn = 1
thin = 1 # tieni tutti i multipli di thin

res = Gibbs_sampler(data,niter,nburn,thin,options,seed=270999,print=F)
```

If you are here, you are very luck. Don't even look at what's below if the upper code doesn't run. Fool.

Estimation

```{r}
Omega_est = matrix(0,p,p)
for(i in 1:length(res$Omega))
  Omega_est = Omega_est + res$Omega[[i]]

Omega_est = Omega_est/length(res$Omega)

round(Omega_true,digits = 3)
round(Omega_est,digits = 3)

# Plot Omega_true
ACutils::ACheatmap(Omega_true,use_x11_device = F,horizontal = F, main = "Omega true")

#Plot empirical estimate
ACutils::ACheatmap(solve(cov(data)),use_x11_device = F,horizontal = F, main = "Empirical est")

#Plot Omega estimated
ACutils::ACheatmap(Omega_est,use_x11_device = F,horizontal = F, main = "Omega estimated")
```

b)  Fit the model with fixed precision matrix and learn the partition

```{r}
W = solve(cov(data))
nu = max(n,p)

options = set_options( nu=nu, W=W, a_alpha = 3, b_alpha = 3,
                       Omega0=Omega_true, z0=z_true, alpha0 = 3,
                       var_alpha_adp0 = 1, adaptiveAlpha = T,
                       UpdatePartition = T, UpdateOmega = F, UpdateAlpha = T)

niter = 3000
nburn = 1500
thin = 1
source("./funzioni.R")
res = Gibbs_sampler(data,niter,nburn,thin,options,seed=1234,print=F)
```

```{r}
# Traceplot of alpha
plot(res$alpha,type = 'l')
plot(res$var_alpha_adp,type = 'l')

# Diagnosis for the number of clusters

nclus_per_iter = apply(res$Partition, 1, 
                       FUN = function(x){length(unique(x))}) # res$Partition is a n_iter x p matrix
plot(nclus_per_iter,type = 'l')
barplot(table(nclus_per_iter)/length(nclus_per_iter) )


# Compute VI and Binder Loss function to select best partition

# Get labels for each iterations for each data point 
part_matrix <- res$Partition # (n_iter x n_data) matrix

# Compute similarity matrix
sim_matrix <- psm(part_matrix)


heatmap(sim_matrix)

binder_sara = minbinder(sim_matrix)
VI_sara = minVI(sim_matrix)

cat('Binder loss \n')
table(binder_sara$cl)
cat('Variance loss \n')
table(VI_sara$cl)
cat('True \n')
counts_true


ACutils::ACheatmap(sim_matrix,use_x11_device = F,horizontal = F, main = "similarity",   center_value = 0.5,
  col.upper = "black",
  col.center = "grey50",
  col.lower = "white")

```

c)  Fit the model when everything is random

```{r}
W = solve(cov(data))
nu = max(n,p)

options = set_options( nu=nu, W=W, a_alpha = 3, b_alpha = 3,
                       Omega0=Omega_true, z0=z_true, alpha0 = 3,
                       var_alpha_adp0 = 1, adaptiveAlpha = T,
                       UpdatePartition = T, UpdateOmega = T, UpdateAlpha = T)

niter = 5000
nburn = 2500
thin = 1
source("./funzioni.R")
res = Gibbs_sampler(data,niter,nburn,thin,options,seed=1234,print=F)
```

Assess goodness of matrix estimation

```{r}
Omega_est = matrix(0,p,p)
for(i in 1:length(res$Omega))
  Omega_est = Omega_est + res$Omega[[i]]

Omega_est = Omega_est/length(res$Omega)

# Plot Omega_true
ACutils::ACheatmap(Omega_true,use_x11_device = F,horizontal = F, main = "Omega true")

#Plot empirical estimate
ACutils::ACheatmap(solve(cov(data)),use_x11_device = F,horizontal = F, main = "Empirical est")

#Plot Omega estimated
ACutils::ACheatmap(Omega_est,use_x11_device = F,horizontal = F, main = "Omega estimated")
```

Assess goodness of clustering

```{r}
# Traceplot of alpha
plot(res$alpha,type = 'l')
plot(res$var_alpha_adp,type = 'l')

# Diagnosis for the number of clusters

nclus_per_iter = apply(res$Partition, 1, 
                       FUN = function(x){length(unique(x))}) # res$Partition is a n_iter x p matrix
plot(nclus_per_iter,type = 'l')
barplot(table(nclus_per_iter)/length(nclus_per_iter) )


# Compute VI and Binder Loss function to select best partition

# Get labels for each iterations for each data point 
part_matrix <- res$Partition # (n_iter x n_data) matrix

# Compute similarity matrix
sim_matrix <- psm(part_matrix)


heatmap(sim_matrix)

binder_sara = minbinder(sim_matrix)
VI_sara = minVI(sim_matrix)

cat('Binder loss \n')
table(binder_sara$cl)
cat('Variance loss \n')
table(VI_sara$cl)
cat('True \n')
counts_true

```

## Generate data as done in the paper

```{r}
z_true = c(1,1,
           2,2,2,
           3,3,3,
           4,4,4,4)
counts_true = as.vector(table(z_true))
Nclust_true  = length(counts_true)

p = length(z_true)
n = 100
p_in = 1
p_out = 0
nu = n

# Generate precision and covariance matrices
seed=4567
Omega = matrix(0,nrow = p,ncol = p)
for(i in 1:(p-1)){
  for(j in (i+1):p){
    
    if(z_true[i]==z_true[j]){
      # draw with prob p_in
      if(runif(n=1)<p_in)
        Omega[i,j] = 3.3
    }else{
      # draw with proba p_put
        if(runif(n=1)<p_out)
          Omega[i,j] = 3.3
    }
      
  }
}
Omega = Omega + t(Omega)
min_eig = eigen(Omega)$values[p]
Omega_true = Omega + diag(x=abs(min_eig) + 2.2,nrow = p)  
Sigma_true = solve(Omega_true)

# Generate data
data = matrix(NA,nrow = n, ncol = p)
data = t(apply(data, 1, FUN = function(x){ mvtnorm::rmvnorm(n = 1, sigma = Sigma_true)  }))
U = t(data)%*%data


# Plot Omega
ACutils::ACheatmap(Omega_true,use_x11_device = F,horizontal = F, center_value = 0.1)

#Plot empirical estimate
ACutils::ACheatmap(solve(cov(data)),use_x11_device = F,horizontal = F, center_value = 0.1)

```

a)  Fit the model with fixed partition

```{r}
W = solve(cov(data))
nu = max(n,p)

options = set_options( nu=nu, W=W, a_alpha = 3, b_alpha = 3,
                       Omega0=Omega_true, z0=z_true, alpha0 = 3,
                       var_alpha_adp0 = 1, adaptiveAlpha = T,
                       UpdatePartition = F, UpdateOmega = T, UpdateAlpha = F)

niter = 3000
nburn = 1500
thin = 1
source("./funzioni.R")
res = Gibbs_sampler(data,niter,nburn,thin,options,seed=1234,print=F)
```

```{r}
Omega_est = matrix(0,p,p)
for(i in 1:length(res$Omega))
  Omega_est = Omega_est + res$Omega[[i]]

Omega_est = Omega_est/length(res$Omega)

# Plot Omega_true
ACutils::ACheatmap(Omega_true,use_x11_device = F,horizontal = F, main = "Omega true", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")

#Plot empirical estimate
ACutils::ACheatmap(solve(cov(data)),use_x11_device = F,horizontal = F, main = "Empirical est", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")

#Plot Omega estimated
ACutils::ACheatmap(Omega_est,use_x11_device = F,horizontal = F, main = "Omega estimated", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")
```

b)  Fit the model with fixed precision matrix and learn the partition

```{r}
W = solve(cov(data))
nu = max(n,p)

options = set_options( nu=nu, W=W, a_alpha = 3, b_alpha = 3,
                       Omega0=Omega_true, z0=z_true, alpha0 = 3,
                       var_alpha_adp0 = 1, adaptiveAlpha = T,
                       UpdatePartition = T, UpdateOmega = F, UpdateAlpha = T)

niter = 3000
nburn = 1500
thin = 1
source("./funzioni.R")
res = Gibbs_sampler(data,niter,nburn,thin,options,seed=1234,print=F)
```

```{r}
# Traceplot of alpha
plot(res$alpha,type = 'l')
plot(res$var_alpha_adp,type = 'l')

# Diagnosis for the number of clusters

nclus_per_iter = apply(res$Partition, 1, 
                       FUN = function(x){length(unique(x))}) # res$Partition is a n_iter x p matrix
plot(nclus_per_iter,type = 'l')
barplot(table(nclus_per_iter)/length(nclus_per_iter) )


# Compute VI and Binder Loss function to select best partition

# Get labels for each iterations for each data point 
part_matrix <- res$Partition # (n_iter x n_data) matrix

# Compute similarity matrix
sim_matrix <- psm(part_matrix)


heatmap(sim_matrix)

binder_sara = minbinder(sim_matrix)
VI_sara = minVI(sim_matrix)

cat('Binder loss \n')
table(binder_sara$cl)
cat('Variance loss \n')
table(VI_sara$cl)
cat('True \n')
counts_true

# Plot similarity matrix
ACutils::ACheatmap(sim_matrix,use_x11_device = F,horizontal = F, main = "similarity",   center_value = 0.5,
  col.upper = "black",
  col.center = "grey50",
  col.lower = "white")


```

c)  Fit the model when everything is random

```{r}
W = solve(cov(data))
nu = max(n,p)

# Idea for choosing alpha
Kstar = 4 # expected number of clusters
solver = nleqslv::nleqslv(x = 1, fn = function(x){digamma(x+n)-digamma(x) - Kstar/x})
solver$x # final value for alpha
solver$fvec #function value

options = set_options( nu=nu, W=W, a_alpha = solver$x, b_alpha = 1,
                       Omega0=diag(p), z0=z_true, alpha0 = solver$x,
                       var_alpha_adp0 = 1, adaptiveAlpha = T,
                       UpdatePartition = T, UpdateOmega = T, UpdateAlpha = T)

niter = 5000
nburn = 2500
thin = 1
source("./funzioni.R")
res = Gibbs_sampler(data,niter,nburn,thin,options,seed=1234,print=F)
```

Assess goodness of matrix estimation

```{r}
Omega_est = matrix(0,p,p)
for(i in 1:length(res$Omega))
  Omega_est = Omega_est + res$Omega[[i]]

Omega_est = Omega_est/length(res$Omega)

# Plot Omega_true
ACutils::ACheatmap(Omega_true,use_x11_device = F,horizontal = F, main = "Omega true", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")

#Plot empirical estimate
ACutils::ACheatmap(solve(cov(data)),use_x11_device = F,horizontal = F, main = "Empirical est", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")

#Plot Omega estimated
ACutils::ACheatmap(Omega_est,use_x11_device = F,horizontal = F, main = "Omega estimated", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")
```

Assess goodness of clustering

```{r}
# Traceplot of alpha
plot(res$alpha,type = 'l')
plot(res$var_alpha_adp,type = 'l')

# Diagnosis for the number of clusters

nclus_per_iter = apply(res$Partition, 1, 
                       FUN = function(x){length(unique(x))}) # res$Partition is a n_iter x p matrix
plot(nclus_per_iter,type = 'l')
barplot(table(nclus_per_iter)/length(nclus_per_iter) )


# Compute VI and Binder Loss function to select best partition

# Get labels for each iterations for each data point 
part_matrix <- res$Partition # (n_iter x n_data) matrix

# Compute similarity matrix
sim_matrix <- psm(part_matrix)


heatmap(sim_matrix)

binder_sara = minbinder(sim_matrix)
VI_sara = minVI(sim_matrix)

cat('Binder loss \n')
table(binder_sara$cl)
cat('Variance loss \n')
table(VI_sara$cl)
cat('True \n')
counts_true

# Plot similarity matrix
ACutils::ACheatmap(sim_matrix,use_x11_device = F,horizontal = F, main = "similarity",   center_value = 0.5,
  col.upper = "black",
  col.center = "grey50",
  col.lower = "white")

```

Correct clustering estimation but it is not mixing.
