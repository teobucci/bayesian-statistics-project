---
title: "Stochastic Block Model Prior with Ordering Constraints for Gaussian Graphical Models"
output:
    html_document:
        toc: true
        toc_float: true
        number_sections: true
    pdf_document:
        toc: true
        toc_depth: 3
        number_section: true
date: "2023-01-17"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Simulations

## Load the necessary packages

```{r}
suppressWarnings(suppressPackageStartupMessages(library(tidyverse)))
suppressWarnings(suppressPackageStartupMessages(library(ACutils)))
suppressWarnings(suppressPackageStartupMessages(library(mvtnorm)))
suppressWarnings(suppressPackageStartupMessages(library(salso)))
suppressWarnings(suppressPackageStartupMessages(library(FGM)))
suppressWarnings(suppressPackageStartupMessages(library(gmp)))
suppressWarnings(suppressPackageStartupMessages(library(mcclust)))
suppressWarnings(suppressPackageStartupMessages(library(mcclust.ext)))
suppressWarnings(suppressPackageStartupMessages(library(logr)))
```

```{r}
paths = c(
    "src/utility_functions.R",
    "src/bulky_functions.R",
    "src/data_generation.R"
)

for(p in paths){
    path = file.path(p)
    if(file.exists(path)){
        source(path)
    } else {
        cat("File",path,"wasn't found in directory, please check.")
    }
}
```


## Generate data

```{r}
# Define true clustering
z_true = c(1,1,1,1,1,1,1, # cluster 1
           2,2,2,2,2,2,2, # cluster 2
           3,3,3,3,3,3,3, # cluster 3
           4,4,4,4,4,4,4, # cluster 4
           5,5,5,5,
           6,6,6,6,6,
           7,7,7,
           8,8,8,8,8,8,
           9,
           10,
           11) # cluster 

# Define data dimension
p = length(z_true)
n = 500

# z_to_rho(z_true)
# z_to_r(z_true)

# Generate data
sim = Generate_BlockDiagonal(n = n, z_true = z_true)
#sim = Generate_Block(n = n, z_true = z_true)

ACutils::ACheatmap(sim$G,use_x11_device = F,horizontal = F, main = "Graph", 
                  center_value = NULL,  
                  col.upper = "black",
                  col.center = "grey50",
                  col.lower = "white")
                  
# Plot Cov
ACutils::ACheatmap(sim$Cov,use_x11_device = F,horizontal = F, main = "Covariance", 
                   center_value = NULL,  
                   col.upper = "black",
                   col.center = "grey50",
                   col.lower = "white")

```

```{r}
Prec_true = sim$Prec # precision matrix
Graph_true = sim$Graph # true graph
Graph_true[col(Graph_true)==row(Graph_true)] = 0 # remove self loops

graph_density = sum(sim$Graph) / (p*(p-1))
```

## Set options for the simulation

```{r}
# https://stackoverflow.com/a/57571028/16222204
# Use TRUE/FALSE instead of T/F

options = set_options(sigma_prior_0=0.5,
                      sigma_prior_parameters=list("a"=1,"b"=1,"c"=1,"d"=1),
                      theta_prior_0=1,
                      theta_prior_parameters=list("c"=1,"d"=1),
                      rho0=p, # start with one group
                      weights_a0=rep(1,p-1),
                      weights_d0=rep(1,p-1),
                      alpha_target=0.234,
                      mu_beta=graph_density,
                      sig2_beta=1/16,
                      d=3,
                      alpha_add=0.5,
                      adaptation_step=1/(p*1000), # as suggested in Benson
                      update_sigma_prior=TRUE,
                      update_theta_prior=TRUE,
                      update_weights=TRUE,
                      update_partition=TRUE,
                      update_graph=TRUE,
                      perform_shuffle=TRUE)
```


## Running the simulation

```{r}

#introducing a proper name
filename=paste('sim',as.character(n), as.character(p),sep='_')
    
log_open(file_name = filename, show_notes=FALSE)
res <- Gibbs_sampler(
    data = sim$data,
    niter = 1500,
    nburn = 300,
    thin = 2,
    options = options,
    seed = 123456,
    print = TRUE
)
log_close()
```

# Posterior analysis

## Partition

Barplot of changepoints

```{r}
r = do.call(rbind, lapply(res$rho, rho_to_r))

# method 1
freq = do.call(rbind, lapply(as.data.frame(r), function(x){sum(abs(diff(x)))}))

# method 2
# freq = do.call(cbind, lapply(as.data.frame(r), function(x){diff(x)}))
# freq[which(freq==-1)] = 0
# freq=colSums(freq)

freq = data.frame(freq=freq)

r_true = z_to_r(z_true)
indexes = which(r_true==1)

barplot(freq$freq,
        names = 1:length(z_true),
        las = 1)
abline(v=indexes, col='red')

z = do.call(rbind, lapply(res$rho, rho_to_z))
```

Number of clusters per iteration

```{r}
num_clusters = do.call(rbind, lapply(res$rho, length))
num_clusters = as.vector(num_clusters)

plot(x =  1:length(num_clusters), y = num_clusters, type = "n", xlab='Iterations', ylab='Number of groups')
lines(x =  1:length(num_clusters), y = num_clusters)

abline(h=length(z_to_rho(z_true)), col='red', lwd=6)
```

## Graph

Kullbackâ€“Leibler
```{r}
kl_dist = do.call(rbind, lapply(res$K, function(k){ACutils::KL_dist(Prec_true,k)}))

last = round(kl_dist[length(kl_dist)],4)
plot(x =  1:length(kl_dist), y = kl_dist, type = "n", xlab='Iterations', ylab='Number of groups', main=paste('KL distance last',last))
lines(x =  1:length(kl_dist), y = kl_dist)
```

```{r}
library(igraph)
plot_graph = function(adjacency_matrix, title){
    # Create the graph object from the adjacency matrix
    g <- graph.adjacency(adjacency_matrix, mode = "undirected")
    # Plot the graph
    plot(g, main=title)
}
```

Extract last graph

```{r}
last_G = res$G[[length(res$G)]]
```

Criterion 1 to select the threshold (shouldn't work very well).

```{r}
threshold = 0.5
```

Criterion 2 to select the threshold

```{r}
threshold = 0
for(threshold_i in seq(0,1,0.001)){
    BFDR_graph_num = 0
    BFDR_graph_den = 0
    id_graph = matrix(0,p,p)
    id_graph[which(last_G>threshold_i)] = 1
    for(k in 1:p){
        for(j in 1:k){
        BFDR_graph_num <- BFDR_graph_num + (1-last_G[k,j])*(id_graph[k,j])
        BFDR_graph_den <- BFDR_graph_den + id_graph[k,j]
        }
    }
    BFDR <- BFDR_graph_num/BFDR_graph_den
    if(BFDR < 0.05) { # tweak, lower = more restrictive
        threshold = threshold_i
        break
    }
}
```

Inspect the threshold

```{r}
threshold
```

Select the graph and plot it against the original

```{r}
final_graph <- matrix(0,p,p)
final_graph[which(last_G>threshold)] = 1
par(mfrow=c(2,1))
plot_graph(final_graph, 'Estimated')
plot_graph(Graph_true, 'True')
par(mfrow=c(1,1))
```

Fancy stuff work in progress

```{r}
library(tidygraph)
library(ggraph)
g <- as_tbl_graph(final_graph, directed = F)
# Plot the graph
ggraph(g, layout='stress') + geom_edge_link() + geom_node_point()
```

## Traceplot of the random index

```{r}
library (fossil) #for rand index. Not sure it is the exact function 

#Recomputing zeta 
z = do.call(rbind, lapply(res$rho, rho_to_z))

#Computing rand index for each iteration
rand_index = apply(z, 1, rand.index, z_true)

#Plotting the traceplot of the index
plot(rand_index,type = 'l')

#index of the first iteration  
first_rand_index=rand_index[1]
first_rand_index

#Index of the last iteration
last_rand_index=rand_index[length(rand_index)]
last_rand_index

```


